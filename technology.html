<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>news</title>
    <link rel="stylesheet" href="newsstyle.css">
</head>

<body>
    <header>
        <div class="navmain  ">
            <div class="border home  ">
                <a href="home.html"><i>WorldEcho</i></a>
            </div>
            <div class="border"><a href="news.html">International</a></div>
            <div class="border"><a href="national.html">National</a></div>
            <div class="border"><a href="sports.html">Sports</a></div>
            <div class="border"><a href="politics.html">Politics</a></div>
            <div class="border"><a href="technology.html">Technology</a></div>
        </div>
    </header>
    <br>
    <br>

    <h1>About 83% Indians have lost money in AI voice scams</h1>
    <br>
    <img src="file:///C:/Users/Admin/AppData/Local/Microsoft/Windows/INetCache/IE/FG77QCV8/image5[1].webp"
        class="center">
    <div class="hero-msg">

    </div>
    </div>
    <br>
    <br>
    <h4>What is happening right now</h4>
    <br>
    <p>According to a report by McAfee, more than half (69%) of Indians think they don't know or cannot tell the
        difference between an AI voice and real voice. About half (47%) of Indian adults have experienced or know
        someone who has experienced some kind of AI voice scam, which is almost double the global average (25%). With
        the rise in popularity and adoption of artificial intelligence (AI) tools, it is now easier to manipulate
        images, videos and voices of friends and family members. Earlier this year, it was reported that cyber criminals
        are using AI-powered voice to target people. According to a new report, India tops the list of victims and 83%
        of Indians have lost money in these types of scams.
        Scammers are using AI to sound like family members in distress and Indians are falling for such scams. According
        to a report by McAfee, more than half (69%) of Indians think they don't know or cannot tell the difference
        between an AI voice and real voice.
        Furthermore, about half (47%) of Indian adults have experienced or know someone who has experienced some kind of
        AI voice scam, which is almost double the global average (25%), said the report, titled 'The Artificial
        Imposter'. "AI technology is fueling a rise in online voice scams, with just three seconds of audio required to
        clone a person's voice. The survey was conducted with 7,054 people from seven countries, including India," the
        report highlighted.
    </p>
    <br>
    <br>
    <h4>Indians losing money</h4>
    <br>
    <p>According to a McAfee report, 83% of Indian victims said they had a loss of money- with 48% losing over Rs
        50,000.
        "Artificial Intelligence brings incredible opportunities, but with any technology there is always the potential
        for it to be used maliciously in the wrong hands. This is what we're seeing today with the access and ease of
        use of AI tools helping cybercriminals to scale their efforts in increasingly convincing ways," said Steve
        Grobman, McAfee CTO.
    </p>
    <br>
    <img src="https://media.tegna-media.com/assets/VERIFY/images/cdafb0db-b637-43a4-93f2-6004e189210d/cdafb0db-b637-43a4-93f2-6004e189210d_1920x1080.jpg"
        class="pic">
    <br>
    <h4>Why AI voice colning is dangerous</h4>
    <br>
    <p>Everybody's voice is unique, which essentially means that it is the spoken equivalent of a biometric fingerprint.
        Hence, speaking is an accepted way of establishing trust.
        But with 86% of Indian adults sharing their voice data online or in recorded notes at least once a week (via
        social media, voice notes and more), voice cloning has become a powerful tool for cybercriminals.
    </p>
    <br>
    <h4>More Findings Of The reports</h4>
    <br>
    <p>McAfee said that more than half (66%) of the Indian respondents said they would reply to a voicemail or voice
        note purporting to be from a friend or loved one in need of money.
        "Particularly if they thought the request had come from their parent (46%), partner or spouse (34%), or child
        (12%). Messages most likely to elicit a response were those claiming that the sender had been robbed (70%), was
        involved in a car incident (69%), lost their phone or wallet (65%) or needed help while travelling abroad (62%),
        the report found.
        There has been a rise of deepfakes and disinformation which has led to people being more wary of what they see
        online. According to the survey, 27% of Indian adults said they are now less trusting of social media than ever
        before and 43% being concerned over the rise of misinformation or disinformation.
    </p>
    <br>
    <img src="https://nypost.com/wp-content/uploads/sites/2/2023/09/NYPICHPDPICT000048884306.jpg?quality=75&strip=all&w=744"
        class="pic">
    <br>
    <h4>AI Scam Alert! How to spot fake video calls, deepfake tecnology to stay safe</h4>
    <br>
    <p>Nowadays, people usually opt for video calls to have a
        conversation with their family, friends, or colleagues across the
        world. You are completely aware of the person's face, voice, and
        surroundings, but what if you see something unusual during the
        video call like a different background, video size, video quality,
        any watermark, contact information, etc? Be aware! you can be
        defrauded. Yes! The growing technology, especially artificial intelligence, has made it more convincing for
        fraudsters to dupe innocent people's money globally. A similar incident took place in northern China where a man
        found himself the victim of a Al-driven video call scam involving deepfake technology. With the help of
        Al-powered face-swapping technology, the scammer posed as the victim's close friend during a video call and
        persuaded him to transfer an amount of 4.3 million yuan (over â‚¹5 crore). The incident took place in Baotou,
        China. The victim realized that he has been duped when his real friend expressed ignorance about the call. 
    </p>
    <br>
    <p>Local police, in an official statement, revealed that they had managed to recover most of the stolen money and working
        diligently to trace the remaining amount, according to a report published by Reuters.
        Following the growing threat of Al-driven scams, China has been actively tightening its scrutiny of such
        technology and implemented new rules in January this year to provide legal protection for victims.
        Hence, the question arises of how to spot a fake video call. There are some tricks to skirt these issues like
        fake contact number, fake names, unusual background, etc. Take a look at the small signs regarding a fake video
        call,
        1 Video quality: If you observe, the quality of the fake video is
        usually poor. Always check for watermarks or other signs as the fake video comes from an online source.
        2 Contact information: One should check if the person calling you on your contact list or does the name mean
        anything to you. Also, you need to be sure of the contact name appearing on the video call and the contact
        information.
    </p>
    <br>



    <img src="https://images.tech.co/wp-content/uploads/2023/05/02081746/tell-the-difference-mcafee.jpg" class="pic">
    <br>


    <p>_______________________________________________________________________________________________________________________________________________________________
    </p>
    <br>
    <br>
    <br>
    <br>

</body>
<footer>
    <div class="foot-panel">
        <ul>
            <h5>Get to know us</h5>
            <a>Contact us</a>
            <a>About us</a>

        </ul>
        <ul>
            <h5>About You</h5>
            <a>Terms and Conditions</a>
            <a>Privacy Policy</a>

        </ul>
        <ul>
            <h5>Archives</h5>
            <a>Newsletter</a>
            <a>Weather Today</a>

        </ul>
        <ul>
            <h5>Advertisement</h5>
            <a>Create Your Own Ad</a>
            <a>Sponsorship</a>

        </ul>
    </div>
</footer>